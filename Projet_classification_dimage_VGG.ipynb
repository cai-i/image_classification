{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZcN0oxDIb5s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# pour accéder aux fichiers\n",
        "import os\n",
        "# faire des opérations sur images\n",
        "import cv2\n",
        "# pour afficher images\n",
        "import PIL\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# afficher predictions\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "\n",
        "urls = [\"https://github.com/cai-i/image_classification/raw/train_test/resized_images.zip\"] \n",
        "for url in urls :\n",
        "  data_dir = tf.keras.utils.get_file(origin=url, extract=False)\n",
        "\n",
        "  with zipfile.ZipFile(data_dir, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/datasets')"
      ],
      "metadata": {
        "id": "ALSgUc2MIm9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path('/content/datasets/resized_images')\n",
        "train_dir = pathlib.Path('/content/datasets/resized_images/train')\n",
        "val_dir = pathlib.Path('/content/datasets/resized_images/val')\n",
        "test_dir = pathlib.Path('/content/datasets/resized_images/test')"
      ],
      "metadata": {
        "id": "wNMC5FRFInA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['abeille', 'guepe', 'frelon']\n",
        "class_names_label = { class_name:i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "print(class_names_label)"
      ],
      "metadata": {
        "id": "eZhrgIt3IsEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "\n",
        "  dir = '/content/datasets/resized_images/'\n",
        "  datasets = ['train', 'val', 'test']\n",
        "\n",
        "  output = []\n",
        "\n",
        "  for dataset in datasets:\n",
        "    path = os.path.join(dir, dataset)\n",
        "    images=[]\n",
        "    labels=[]\n",
        "\n",
        "    for category in os.listdir(path):\n",
        "      label= class_names_label[category]\n",
        "      cat_path = os.path.join(path, category)\n",
        "\n",
        "      for img in os.listdir(cat_path):\n",
        "        img_path = os.path.join(cat_path, img)\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        # append to lists\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "    \n",
        "    images = np.array(images, dtype='float32')\n",
        "    labels = np.array(labels, dtype = 'int32')\n",
        "\n",
        "    output.append((images, labels))\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "sZ-hV866IsGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_imgs, train_labels), (val_imgs, val_labels), (test_imgs, test_labels) = load_data()"
      ],
      "metadata": {
        "id": "C3wX3zBeIsJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hzi557l4IsLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "jL1mabseIsOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_vgg = VGG16(weights='imagenet', include_top=False)\n",
        "model_vgg = Model(inputs=model_vgg.inputs, outputs=model_vgg.layers[-5].output)"
      ],
      "metadata": {
        "id": "939eVQZqIsQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = model_vgg.predict(train_imgs)\n",
        "val_features = model_vgg.predict(val_imgs)\n",
        "test_features = model_vgg.predict(test_imgs)"
      ],
      "metadata": {
        "id": "1d7Qfd57InGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Activation\n",
        "\n",
        "model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "input_shape = model.layers[-4].get_input_shape_at(0)\n",
        "layer_input = Input(shape=(9,9,512))\n",
        "\n",
        "x = layer_input\n",
        "for layer in model.layers[-4::1]:\n",
        "  x = layer(x)\n",
        "\n",
        "x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size = (2,2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(100, activation = 'relu')(x)\n",
        "x = Dense(6, activation='softmax')(x)\n",
        "\n",
        "# create the model\n",
        "model = Model(layer_input, x)"
      ],
      "metadata": {
        "id": "q09dJEMAInIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss= 'sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Jj3VP3OYJNly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size= 128,\n",
        "    epochs=20,\n",
        "    validation_data= (val_features,val_labels)\n",
        ")"
      ],
      "metadata": {
        "id": "s2PJbYHUJNpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yIw7fD09JNs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "JFo7C2GCJbcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = model.evaluate(test_imgs, test_labels)"
      ],
      "metadata": {
        "id": "SVhaVY8kJbfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_imgs)\n",
        "pred_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(classification_report(test_labels, pred_labels))"
      ],
      "metadata": {
        "id": "d1oq8RXOJbiE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}